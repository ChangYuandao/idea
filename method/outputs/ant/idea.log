[2025-11-20 19:59:40,052][root][INFO] - Idea Root Dir: /home/changyuandao/changyuandao/paperProject/idea/method
[2025-11-20 19:59:40,052][root][INFO] - IsaacGymEnvs Root Dir: /home/changyuandao/changyuandao/paperProject/idea/IsaacGymEnvs/isaacgymenvs
[2025-11-20 19:59:40,052][root][INFO] - Workspace: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant
[2025-11-20 19:59:40,052][root][INFO] - Project Root: /home/changyuandao/changyuandao/paperProject/idea/method
[2025-11-20 19:59:40,131][root][INFO] - Using LLM: qwen3-coder-plus
[2025-11-20 19:59:40,131][root][INFO] - Task: Ant
[2025-11-20 19:59:40,131][root][INFO] - Task Description: to make the ant run forward as fast as possible
[2025-11-20 19:59:40,131][root][INFO] - Env Parent: isaac
[2025-11-20 19:59:40,147][root][INFO] - === Iteration 0 ===
[2025-11-20 19:59:40,147][root][INFO] - Role: EXPLORER
[2025-11-20 19:59:40,147][root][INFO] - Generating 1 samples with qwen3-coder-plus
[2025-11-20 19:59:47,584][httpx][INFO] - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions "HTTP/1.1 200 OK"
[2025-11-20 19:59:47,597][root][INFO] - Iteration 0: Prompt Tokens: 1287, Completion Tokens: 448, Total Tokens: 1735
[2025-11-20 19:59:47,597][root][INFO] - Role: CONSERVATOR
[2025-11-20 19:59:47,598][root][INFO] - Generating 1 samples with qwen3-coder-plus
[2025-11-20 19:59:55,921][httpx][INFO] - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions "HTTP/1.1 200 OK"
[2025-11-20 19:59:55,923][root][INFO] - Iteration 0: Prompt Tokens: 1276, Completion Tokens: 557, Total Tokens: 1833
[2025-11-20 19:59:55,923][root][INFO] - Role: INTEGRATOR
[2025-11-20 19:59:55,924][root][INFO] - Generating 1 samples with qwen3-coder-plus
[2025-11-20 20:00:00,884][httpx][INFO] - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions "HTTP/1.1 200 OK"
[2025-11-20 20:00:00,885][root][INFO] - Iteration 0: Prompt Tokens: 1282, Completion Tokens: 308, Total Tokens: 1590
[2025-11-20 20:00:00,885][root][INFO] - Iteration 0: role_EXPLORER Processing Code Run 0
[2025-11-20 20:00:09,829][root][INFO] - Iteration 0: Code Run 0 successfully training!
[2025-11-20 20:00:09,829][root][INFO] - Iteration 0: role_CONSERVATOR Processing Code Run 0
[2025-11-20 20:00:19,212][root][INFO] - Iteration 0: Code Run 0 successfully training!
[2025-11-20 20:00:19,212][root][INFO] - Iteration 0: role_INTEGRATOR Processing Code Run 0
[2025-11-20 20:00:28,739][root][INFO] - Iteration 0: Code Run 0 successfully training!
[2025-11-20 20:00:28,739][root][INFO] - Role: EXPLORER - Processing RL Results
[2025-11-20 20:02:35,506][tensorboard][INFO] - No path found after /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/Iteration_0/EXPLORER_0/runs/antgpt/summaries/events.out.tfevents.1763640004.changyuandao-020318
[2025-11-20 20:02:35,508][root][INFO] - Role: CONSERVATOR - Processing RL Results
[2025-11-20 20:02:35,772][tensorboard][INFO] - No path found after /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/Iteration_0/CONSERVATOR_0/runs/antgpt/summaries/events.out.tfevents.1763640013.changyuandao-020318
[2025-11-20 20:02:35,776][root][INFO] - Role: INTEGRATOR - Processing RL Results
[2025-11-20 20:02:35,873][tensorboard][INFO] - No path found after /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/Iteration_0/INTEGRATOR_0/runs/antgpt/summaries/events.out.tfevents.1763640022.changyuandao-020318
[2025-11-20 20:02:35,874][root][INFO] - Selecting the best reward function across all roles...
[2025-11-20 20:02:35,874][root][INFO] - [EXPLORER] Best sample 0: Success=3.9848898220062257, Corr=0.9996811628239407
[2025-11-20 20:02:35,875][root][INFO] - [CONSERVATOR] Best sample 0: Success=1.5935351600646972, Corr=0.7761565910991235
[2025-11-20 20:02:35,875][root][INFO] - [INTEGRATOR] Best sample 0: Success=-1.3731453227996826, Corr=-0.9986186196933124
[2025-11-20 20:02:35,875][root][INFO] - Iteration 0 - üèÜ Global Best Reward Function from Role [EXPLORER] - Response ID: 0, 
[2025-11-20 20:02:35,875][root][INFO] - üìÑ Best reward function file: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/env_iter0_role_EXPLORER_response0_rewardonly.py
[2025-11-20 20:02:35,875][root][INFO] - Found reward expression: (forward_reward+speed_reward+0.5*lateral_movement_penalty+0.1*vertical_movement_penalty+0.01*energy_penalty)reward_components={"forward_reward":forward_reward,"speed_reward":speed_reward,"lateral_penalty":lateral_movement_penalty,"vertical_penalty":vertical_movement_penalty,"energy_penalty":energy_penalty}
[2025-11-20 20:02:35,876][root][INFO] - Found weighted term: 0.5 * lateral_movement_penalty
[2025-11-20 20:02:35,876][root][INFO] - Found weighted term: 0.1 * vertical_movement_penalty
[2025-11-20 20:02:35,876][root][INFO] - Found weighted term: 0.01 * energy_penalty
[2025-11-20 20:02:35,876][root][INFO] - Found implicit term: 1.0 * forward_reward
[2025-11-20 20:02:35,876][root][INFO] - Found implicit term: 1.0 * speed_reward
[2025-11-20 20:02:35,876][root][INFO] - Found implicit term: 1.0 * lateral_penalty
[2025-11-20 20:02:35,876][root][INFO] - Found implicit term: 1.0 * vertical_penalty
[2025-11-20 20:02:35,876][root][INFO] - === Extracted 7 parameters ===
[2025-11-20 20:02:35,876][root][INFO] -   lateral_movement_penalty_weight: 0.5 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   vertical_movement_penalty_weight: 0.1 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   energy_penalty_weight: 0.01 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   forward_reward_weight: 1.0 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   speed_reward_weight: 1.0 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   lateral_penalty_weight: 1.0 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   vertical_penalty_weight: 1.0 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] - Extracted 7 parameters:
[2025-11-20 20:02:35,876][root][INFO] -   lateral_movement_penalty_weight: 0.5000 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   vertical_movement_penalty_weight: 0.1000 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   energy_penalty_weight: 0.0100 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   forward_reward_weight: 1.0000 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   speed_reward_weight: 1.0000 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   lateral_penalty_weight: 1.0000 (range: [0.5, 5.0])
[2025-11-20 20:02:35,876][root][INFO] -   vertical_penalty_weight: 1.0000 (range: [0.5, 5.0])
[2025-11-20 20:02:35,911][root][INFO] - Starting Preference Learning for Iteration 0
[2025-11-20 20:02:35,911][root][INFO] - Checkpoint path: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/Iteration_0/EXPLORER_0/runs/antgpt/nn/AntGPT.pth
[2025-11-20 20:02:35,911][root][INFO] - Step 1: Collecting trajectories...
[2025-11-20 20:02:35,911][root][INFO] - Collecting 10 trajectories from checkpoint: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/Iteration_0/EXPLORER_0/runs/antgpt/nn/AntGPT.pth
[2025-11-20 20:02:35,911][root][INFO] - Output directory: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant
[2025-11-20 20:02:35,927][root][INFO] - Rollout process started (PID: 453500)
[2025-11-20 20:02:35,927][root][INFO] - Log file: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/rollout.log
[2025-11-20 20:02:45,937][root][INFO] - ‚úÖ Trajectory collection completed successfully
[2025-11-20 20:02:45,937][root][INFO] - ‚úÖ Trajectory file found: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/iter0_trajectories.pkl
[2025-11-20 20:02:45,937][root][INFO] - File size: 426.17 KB
[2025-11-20 20:02:45,937][root][INFO] - Step 2: Loading trajectories...
[2025-11-20 20:02:45,939][root][INFO] - Step 3: Generating preference pairs...
[2025-11-20 20:02:45,939][root][INFO] - Using evaluation functions to generate preferences...
[2025-11-20 20:02:45,939][root][INFO] - [Preference Buffer] Loading evaluation functions from /home/changyuandao/changyuandao/paperProject/idea/method/utils/prompts/evaluate_function/Ant
[2025-11-20 20:02:45,940][root][INFO] - Loaded evaluation function: GOAL_1
[2025-11-20 20:02:45,940][root][INFO] - Loaded evaluation function: GOAL_2
[2025-11-20 20:02:45,940][root][INFO] - Loaded evaluation function: GOAL_3
[2025-11-20 20:02:45,941][root][INFO] - Loaded evaluation function: GOAL_4
[2025-11-20 20:02:45,941][root][INFO] - Loaded evaluation function: GOAL_5
[2025-11-20 20:02:45,942][root][INFO] - Loaded evaluation function: SAFE_1
[2025-11-20 20:02:45,942][root][INFO] - Loaded evaluation function: SAFE_2
[2025-11-20 20:02:45,942][root][INFO] - Loaded evaluation function: SAFE_3
[2025-11-20 20:02:45,943][root][INFO] - Loaded evaluation function: SAFE_4
[2025-11-20 20:02:45,943][root][INFO] - Loaded evaluation function: SAFE_5
[2025-11-20 20:02:45,944][root][INFO] - Loaded evaluation function: EFFICIENCY_1
[2025-11-20 20:02:45,944][root][INFO] - Loaded evaluation function: EFFICIENCY_2
[2025-11-20 20:02:45,944][root][INFO] - Loaded evaluation function: EFFICIENCY_3
[2025-11-20 20:02:45,945][root][INFO] - Loaded evaluation function: EFFICIENCY_4
[2025-11-20 20:02:45,945][root][INFO] - Loaded evaluation function: EFFICIENCY_5
[2025-11-20 20:02:45,945][root][INFO] - [Preference Buffer] Loaded 15 evaluation functions
[2025-11-20 20:02:45,945][root][INFO] -   GOAL: 5 functions
[2025-11-20 20:02:45,945][root][INFO] -   SAFE: 5 functions
[2025-11-20 20:02:45,945][root][INFO] -   EFFICIENCY: 5 functions
[2025-11-20 20:02:45,945][root][INFO] - [Preference Buffer] Comparing 10 trajectories...
[2025-11-20 20:02:45,978][root][INFO] -   Compared Trajectory 0 vs Trajectory 1: Labels = [0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]
[2025-11-20 20:02:45,978][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:45,978][root][INFO] -     Segment 1: Trajectory 1 > Trajectory 0, Steps [76:83] (7 steps)
[2025-11-20 20:02:46,009][root][INFO] -   Compared Trajectory 0 vs Trajectory 2: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1]
[2025-11-20 20:02:46,009][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:46,009][root][INFO] -     Segment 1: Trajectory 2 > Trajectory 0, Steps [95:100] (5 steps)
[2025-11-20 20:02:46,040][root][INFO] -   Compared Trajectory 0 vs Trajectory 3: Labels = [0, 0, -1, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1]
[2025-11-20 20:02:46,040][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,072][root][INFO] -   Compared Trajectory 0 vs Trajectory 4: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, -1, 0, 0, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, 0, 0, 0, -1, 0, 0, 0, -1, -1, 0, 0, 0, -1, -1]
[2025-11-20 20:02:46,072][root][INFO] -   ‚úÖ Found 3 preference segment(s)
[2025-11-20 20:02:46,072][root][INFO] -     Segment 1: Trajectory 4 > Trajectory 0, Steps [40:45] (5 steps)
[2025-11-20 20:02:46,072][root][INFO] -     Segment 2: Trajectory 4 > Trajectory 0, Steps [54:60] (6 steps)
[2025-11-20 20:02:46,072][root][INFO] -     Segment 3: Trajectory 4 > Trajectory 0, Steps [76:81] (5 steps)
[2025-11-20 20:02:46,103][root][INFO] -   Compared Trajectory 0 vs Trajectory 5: Labels = [0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]
[2025-11-20 20:02:46,103][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:46,103][root][INFO] -     Segment 1: Trajectory 5 > Trajectory 0, Steps [60:67] (7 steps)
[2025-11-20 20:02:46,103][root][INFO] -     Segment 2: Trajectory 5 > Trajectory 0, Steps [91:100] (9 steps)
[2025-11-20 20:02:46,135][root][INFO] -   Compared Trajectory 0 vs Trajectory 6: Labels = [0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, -1, 0, -1, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1]
[2025-11-20 20:02:46,135][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,166][root][INFO] -   Compared Trajectory 0 vs Trajectory 7: Labels = [0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, -1, 0, -1, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, -1]
[2025-11-20 20:02:46,166][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:46,166][root][INFO] -     Segment 1: Trajectory 7 > Trajectory 0, Steps [77:82] (5 steps)
[2025-11-20 20:02:46,197][root][INFO] -   Compared Trajectory 0 vs Trajectory 8: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1]
[2025-11-20 20:02:46,197][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,228][root][INFO] -   Compared Trajectory 0 vs Trajectory 9: Labels = [0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, -1, -1]
[2025-11-20 20:02:46,228][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:46,229][root][INFO] -     Segment 1: Trajectory 9 > Trajectory 0, Steps [5:10] (5 steps)
[2025-11-20 20:02:46,229][root][INFO] -     Segment 2: Trajectory 9 > Trajectory 0, Steps [76:82] (6 steps)
[2025-11-20 20:02:46,260][root][INFO] -   Compared Trajectory 1 vs Trajectory 2: Labels = [0, 0, 0, -1, 0, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, -1, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:46,260][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,291][root][INFO] -   Compared Trajectory 1 vs Trajectory 3: Labels = [-1, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, 0, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,291][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:46,291][root][INFO] -     Segment 1: Trajectory 3 > Trajectory 1, Steps [0:6] (6 steps)
[2025-11-20 20:02:46,322][root][INFO] -   Compared Trajectory 1 vs Trajectory 4: Labels = [-1, 0, -1, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, -1, 0, 0, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:46,322][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,353][root][INFO] -   Compared Trajectory 1 vs Trajectory 5: Labels = [-1, 0, 0, -1, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, -1, 0, -1, -1, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,353][root][INFO] -   ‚úÖ Found 3 preference segment(s)
[2025-11-20 20:02:46,353][root][INFO] -     Segment 1: Trajectory 5 > Trajectory 1, Steps [10:15] (5 steps)
[2025-11-20 20:02:46,353][root][INFO] -     Segment 2: Trajectory 5 > Trajectory 1, Steps [22:32] (10 steps)
[2025-11-20 20:02:46,353][root][INFO] -     Segment 3: Trajectory 5 > Trajectory 1, Steps [89:94] (5 steps)
[2025-11-20 20:02:46,384][root][INFO] -   Compared Trajectory 1 vs Trajectory 6: Labels = [0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, 0, 0, 0, 0, -1, 0, -1]
[2025-11-20 20:02:46,384][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,416][root][INFO] -   Compared Trajectory 1 vs Trajectory 7: Labels = [-1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, -1, -1, 0, 0, 0, -1]
[2025-11-20 20:02:46,416][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,447][root][INFO] -   Compared Trajectory 1 vs Trajectory 8: Labels = [-1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:46,447][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:46,447][root][INFO] -     Segment 1: Trajectory 8 > Trajectory 1, Steps [0:5] (5 steps)
[2025-11-20 20:02:46,447][root][INFO] -     Segment 2: Trajectory 8 > Trajectory 1, Steps [34:39] (5 steps)
[2025-11-20 20:02:46,478][root][INFO] -   Compared Trajectory 1 vs Trajectory 9: Labels = [-1, -1, -1, -1, 0, -1, -1, 0, 0, -1, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,478][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,509][root][INFO] -   Compared Trajectory 2 vs Trajectory 3: Labels = [-1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,509][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,541][root][INFO] -   Compared Trajectory 2 vs Trajectory 4: Labels = [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, 0, 0, -1, -1, 0, 0, 0, 0, -1, -1]
[2025-11-20 20:02:46,541][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:46,541][root][INFO] -     Segment 1: Trajectory 4 > Trajectory 2, Steps [0:7] (7 steps)
[2025-11-20 20:02:46,541][root][INFO] -     Segment 2: Trajectory 4 > Trajectory 2, Steps [80:87] (7 steps)
[2025-11-20 20:02:46,572][root][INFO] -   Compared Trajectory 2 vs Trajectory 5: Labels = [-1, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,572][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:46,572][root][INFO] -     Segment 1: Trajectory 5 > Trajectory 2, Steps [65:70] (5 steps)
[2025-11-20 20:02:46,603][root][INFO] -   Compared Trajectory 2 vs Trajectory 6: Labels = [-1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, -1, 0, 0, 0, 0]
[2025-11-20 20:02:46,603][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,634][root][INFO] -   Compared Trajectory 2 vs Trajectory 7: Labels = [-1, 0, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, -1, 0, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:46,634][root][INFO] -   ‚úÖ Found 3 preference segment(s)
[2025-11-20 20:02:46,634][root][INFO] -     Segment 1: Trajectory 7 > Trajectory 2, Steps [48:53] (5 steps)
[2025-11-20 20:02:46,634][root][INFO] -     Segment 2: Trajectory 7 > Trajectory 2, Steps [77:87] (10 steps)
[2025-11-20 20:02:46,634][root][INFO] -     Segment 3: Trajectory 7 > Trajectory 2, Steps [88:93] (5 steps)
[2025-11-20 20:02:46,666][root][INFO] -   Compared Trajectory 2 vs Trajectory 8: Labels = [-1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, -1, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, -1, -1, 0, -1, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:46,666][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:46,666][root][INFO] -     Segment 1: Trajectory 8 > Trajectory 2, Steps [0:5] (5 steps)
[2025-11-20 20:02:46,666][root][INFO] -     Segment 2: Trajectory 8 > Trajectory 2, Steps [88:94] (6 steps)
[2025-11-20 20:02:46,697][root][INFO] -   Compared Trajectory 2 vs Trajectory 9: Labels = [-1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,697][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:46,697][root][INFO] -     Segment 1: Trajectory 9 > Trajectory 2, Steps [81:86] (5 steps)
[2025-11-20 20:02:46,728][root][INFO] -   Compared Trajectory 3 vs Trajectory 4: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, -1, 0, 0, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, -1, 0, 0, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, 0, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, 0, 0, 0, -1, 0, -1, 0, -1, -1, -1, 0, 0, -1, -1, 0, 0, 0, -1, -1]
[2025-11-20 20:02:46,728][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:46,728][root][INFO] -     Segment 1: Trajectory 4 > Trajectory 3, Steps [56:62] (6 steps)
[2025-11-20 20:02:46,728][root][INFO] -     Segment 2: Trajectory 4 > Trajectory 3, Steps [71:76] (5 steps)
[2025-11-20 20:02:46,759][root][INFO] -   Compared Trajectory 3 vs Trajectory 5: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:46,759][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,790][root][INFO] -   Compared Trajectory 3 vs Trajectory 6: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, -1, 0, 0, -1, 0, -1, 0, -1, 0, -1, -1, -1, 0, -1, 0, 0, -1, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, -1, -1, -1, 0, 0, -1, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,790][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,821][root][INFO] -   Compared Trajectory 3 vs Trajectory 7: Labels = [0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, -1, 0, -1]
[2025-11-20 20:02:46,822][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:46,822][root][INFO] -     Segment 1: Trajectory 7 > Trajectory 3, Steps [40:47] (7 steps)
[2025-11-20 20:02:46,852][root][INFO] -   Compared Trajectory 3 vs Trajectory 8: Labels = [0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1, -1, -1, 0, 0, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:46,853][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:46,853][root][INFO] -     Segment 1: Trajectory 8 > Trajectory 3, Steps [63:69] (6 steps)
[2025-11-20 20:02:46,884][root][INFO] -   Compared Trajectory 3 vs Trajectory 9: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, -1, -1, 0, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,884][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:46,884][root][INFO] -     Segment 1: Trajectory 9 > Trajectory 3, Steps [63:72] (9 steps)
[2025-11-20 20:02:46,884][root][INFO] -     Segment 2: Trajectory 9 > Trajectory 3, Steps [75:80] (5 steps)
[2025-11-20 20:02:46,915][root][INFO] -   Compared Trajectory 4 vs Trajectory 5: Labels = [0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,915][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,946][root][INFO] -   Compared Trajectory 4 vs Trajectory 6: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,946][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:46,978][root][INFO] -   Compared Trajectory 4 vs Trajectory 7: Labels = [0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:46,979][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,010][root][INFO] -   Compared Trajectory 4 vs Trajectory 8: Labels = [0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, -1, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,010][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,042][root][INFO] -   Compared Trajectory 4 vs Trajectory 9: Labels = [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,042][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,073][root][INFO] -   Compared Trajectory 5 vs Trajectory 6: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,073][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,105][root][INFO] -   Compared Trajectory 5 vs Trajectory 7: Labels = [0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,105][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:47,105][root][INFO] -     Segment 1: Trajectory 7 > Trajectory 5, Steps [76:81] (5 steps)
[2025-11-20 20:02:47,137][root][INFO] -   Compared Trajectory 5 vs Trajectory 8: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]
[2025-11-20 20:02:47,137][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,168][root][INFO] -   Compared Trajectory 5 vs Trajectory 9: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,168][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,199][root][INFO] -   Compared Trajectory 6 vs Trajectory 7: Labels = [0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, 0, -1, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,200][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:47,200][root][INFO] -     Segment 1: Trajectory 7 > Trajectory 6, Steps [10:17] (7 steps)
[2025-11-20 20:02:47,231][root][INFO] -   Compared Trajectory 6 vs Trajectory 8: Labels = [0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,231][root][INFO] -   ‚úÖ Found 1 preference segment(s)
[2025-11-20 20:02:47,231][root][INFO] -     Segment 1: Trajectory 8 > Trajectory 6, Steps [25:31] (6 steps)
[2025-11-20 20:02:47,262][root][INFO] -   Compared Trajectory 6 vs Trajectory 9: Labels = [-1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,263][root][INFO] -   ‚úÖ Found 2 preference segment(s)
[2025-11-20 20:02:47,263][root][INFO] -     Segment 1: Trajectory 9 > Trajectory 6, Steps [5:10] (5 steps)
[2025-11-20 20:02:47,263][root][INFO] -     Segment 2: Trajectory 9 > Trajectory 6, Steps [16:22] (6 steps)
[2025-11-20 20:02:47,294][root][INFO] -   Compared Trajectory 7 vs Trajectory 8: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,294][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,326][root][INFO] -   Compared Trajectory 7 vs Trajectory 9: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,326][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,357][root][INFO] -   Compared Trajectory 8 vs Trajectory 9: Labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2025-11-20 20:02:47,357][root][INFO] -   ‚ö†Ô∏è No strong preference detected
[2025-11-20 20:02:47,357][root][INFO] - 
[Preference Buffer] Summary:
  - Trajectory comparisons: 45
  - Total preference segments: 36
  - Unique preference pairs: 36
[2025-11-20 20:02:47,357][root][INFO] - Step 4: Updating reward function parameters...
[2025-11-20 20:06:47,184][root][INFO] - Step 5: Updating reward function code...
[2025-11-20 20:06:47,185][root][INFO] - Updating reward function with new parameters...
[2025-11-20 20:06:47,185][root][INFO] -   Updated lateral_movement_penalty_weight: 2.784904 * lateral_movement_penalty
[2025-11-20 20:06:47,185][root][INFO] -   Updated vertical_movement_penalty_weight: 2.872568 * vertical_movement_penalty
[2025-11-20 20:06:47,185][root][INFO] -   Updated energy_penalty_weight: 2.641255 * energy_penalty
[2025-11-20 20:06:47,186][root][INFO] -   Updated forward_reward_weight: 2.719379 * forward_reward
[2025-11-20 20:06:47,186][root][INFO] -   Updated speed_reward_weight: 2.383918 * speed_reward
[2025-11-20 20:06:47,186][root][WARNING] -   Weight parameter lateral_penalty_weight (reward: lateral_penalty) not found in total_reward line
[2025-11-20 20:06:47,186][root][WARNING] -   Weight parameter vertical_penalty_weight (reward: vertical_penalty) not found in total_reward line
[2025-11-20 20:06:47,186][root][INFO] - Updated reward function saved to: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/env_iter0_updated_reward.py
[2025-11-20 20:06:47,186][root][INFO] - ‚úÖ Preference learning completed!
[2025-11-20 20:06:47,186][root][INFO] - Updated reward function saved to: /home/changyuandao/changyuandao/paperProject/idea/method/outputs/ant/env_iter0_updated_reward.py
[2025-11-20 20:06:47,186][root][INFO] - 
================================================================================

